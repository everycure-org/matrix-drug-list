{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fce1d40-2c97-4bec-9b73-229396403dfa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01metree\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mElementTree\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mET\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mzipfile\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import json\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import os\n",
    "import string\n",
    "import re\n",
    "\n",
    "def strip_spaces(myString):\n",
    "    _RE_COMBINE_WHITESPACE = re.compile(r\"(?a:\\s+)\")\n",
    "    _RE_STRIP_WHITESPACE = re.compile(r\"(?a:^\\s+|\\s+$)\")\n",
    "    myString = _RE_COMBINE_WHITESPACE.sub(\" \", myString)\n",
    "    myString = _RE_STRIP_WHITESPACE.sub(\"\", myString)\n",
    "    return myString\n",
    "\n",
    "def unzip_file(zip_path, extract_to_folder):\n",
    "    if not os.path.isfile(zip_path):\n",
    "        raise FileNotFoundError(f\"The file {zip_path} does not exist.\")\n",
    "    os.makedirs(extract_to_folder, exist_ok=True) \n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to_folder)\n",
    "       #print(f\"Extracted all contents to {extract_to_folder}\")\n",
    "\n",
    "def extract_active_ingredient(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    ns = {'fda': 'urn:hl7-org:v3'}\n",
    "    active_ingredients = []\n",
    "    for ingredient in root.findall(\".//fda:activeMoiety/fda:name\", ns):\n",
    "        active_ingredients.append(ingredient.text)\n",
    "    return active_ingredients\n",
    "        \n",
    "def getIndications(xmlfilepath):\n",
    "    tree = ET.parse(xmlfilepath)\n",
    "    root = tree.getroot()\n",
    "    ns = {'hl7': 'urn:hl7-org:v3'}\n",
    "    sections = root.findall('.//hl7:section', namespaces=ns)\n",
    "    for section in sections:\n",
    "        codeSection = section.find('.//hl7:code', namespaces=ns)\n",
    "        code = codeSection.get('code') if codeSection is not None else \"no code\"\n",
    "        if code == \"34067-9\":\n",
    "            text_elem = section.find('.//hl7:text', namespaces=ns)\n",
    "            try:\n",
    "                text_content = ''.join(text_elem.itertext()).strip()\n",
    "            except:\n",
    "                print('text_elem was empty')\n",
    "                return \"\"\n",
    "            return strip_spaces(text_content.strip(string.whitespace.replace(\" \", \"\")))\n",
    "        else:\n",
    "            text_elem = None    \n",
    "    return None\n",
    "\n",
    "def get_special_populations_data(xmlfilepath, target):\n",
    "    indicationsNameTable = ['Indications','INDICATIONS', \"INDICATIONS AND USAGE\", \"Indications and Usage\", 'INDICATIONS ', 'Indications and usage', 'INDICATIONS:', 'INDICATIONS & USAGE', 'INDICATIONS AND USAGE:', 'INDICATIONS AND USAGE ', 'INDICATIONS AND USE', '1 INDICATIONS AND USAGE']\n",
    "    tree = ET.parse(xmlfilepath)\n",
    "    root = tree.getroot()\n",
    "    ns = {'hl7': 'urn:hl7-org:v3'}\n",
    "    sections = root.findall('.//hl7:section', namespaces=ns)\n",
    "    for section in sections:\n",
    "        codeSection = section.find('.//hl7:code', namespaces=ns)\n",
    "        code = codeSection.get('code') if codeSection is not None else \"no code\"\n",
    "        if code == target:\n",
    "            text_elem = section.find('.//hl7:text', namespaces=ns)\n",
    "            text_content = ''.join(text_elem.itertext()).strip()\n",
    "            return strip_spaces(text_content.strip(string.whitespace.replace(\" \", \"\")))\n",
    "        else:\n",
    "            text_elem = None\n",
    "        \n",
    "    return None\n",
    "       # if title.strip().replace(\":\", \"\") in indicationsNameTable:\n",
    "          #  return text_content\n",
    "\n",
    "def get_indications_codes(xmlfilepath):\n",
    "    print(\"Finding indications for \", xmlfilepath)\n",
    "    tree = ET.parse(xmlfilepath)\n",
    "    root = tree.getroot()\n",
    "    ns = {'hl7': 'urn:hl7-org:v3'}\n",
    "    sections = root.findall('.//hl7:code', namespaces=ns)\n",
    "    for code in sections:\n",
    "        print(code.get('code'))\n",
    "\n",
    "################################################################\n",
    "## MAIN STARTS HERE ############################################\n",
    "################################################################\n",
    "\n",
    "#TODO: write this into __main__, take location of labels as arg\n",
    "dir = \"/Volumes/MML/dailymed_labels/\"\n",
    "\n",
    "\n",
    "special_populations_data_list = []\n",
    "ingredientsList = []\n",
    "counts = 0\n",
    "foundCounts = 0\n",
    "notFoundCounts = 0\n",
    "\n",
    "dirs = []\n",
    "\n",
    "# TODO: automatically find, download, unzip all of the dailymed folders\n",
    "labelFolders = [\"prescription_1/\", \"prescription_2/\", \"prescription_3/\", \"prescription_4/\", \"prescription_5/\"]\n",
    "\n",
    "target_codes = {\n",
    "    'pediatric': '34081-0',\n",
    "    'geriatric': '34082-8',\n",
    "    'nursing': '34080-2',\n",
    "    'pregnant': '42228-7',\n",
    "    'labor_and_delivery': '34079-4',\n",
    "    'general': '43684-0',\n",
    "    'unclassified': '42229-5',\n",
    "    'contraindications': '34070-3'\n",
    "}\n",
    "\n",
    "for label in labelFolders:\n",
    "    dirs.append(dir+label)\n",
    "    \n",
    "for directory in dirs:\n",
    "    for files in os.listdir(directory):\n",
    "        if files.endswith(\".zip\"):\n",
    "            fpath = directory + files\n",
    "            fileRoot = files.replace(\".zip\",\"\")\n",
    "            dest = directory + fileRoot\n",
    "            #try:\n",
    "            #    unzip_file(fpath,dest)\n",
    "            #except:\n",
    "            #    print(\"failed to unzip file \", fpath)\n",
    "            #    continue\n",
    "            xmlfile=\"\"\n",
    "            for contents in os.listdir(dest):\n",
    "                if contents.endswith(\".xml\"):\n",
    "                    xmlfile=contents.replace(\"._\",\"\")\n",
    "            xmlfilepath = dest+\"/\"+xmlfile\n",
    "            special_populations_data = get_special_populations_data(xmlfilepath, target= target_codes['general'])\n",
    "            active_ingredients = extract_active_ingredient(xmlfilepath)\n",
    "            for ind, item in enumerate(active_ingredients):\n",
    "                active_ingredients[ind]=item.upper()\n",
    "            ingredientsList.append(set(active_ingredients))\n",
    "            if special_populations_data is not None:\n",
    "                special_populations_data_list.append(special_populations_data)\n",
    "                foundCounts += 1\n",
    "                print(foundCounts, \" special populations sections successfully found so far\")\n",
    "            else:\n",
    "                notFoundCounts += 1\n",
    "                print(notFoundCounts, \" special populations sections not found so far, failed to find for \", files)\n",
    "                special_populations_data_list.append(\"\")\n",
    "            counts +=1\n",
    "    \n",
    "print(\"finished ingesting indications\")\n",
    "data = pd.DataFrame({'active ingredient':ingredientsList, 'special populations data':special_populations_data_list})\n",
    "data.to_excel(\"specialPopulations.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a93f5d3-684c-434b-9ad3-adb095c6aa52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
